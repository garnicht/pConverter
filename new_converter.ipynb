{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from weclapp_api import create_article, get_recent_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "    # Try reading the file with different encodings\n",
    "    encodings = ['utf-8', 'latin1', 'cp1252', 'windows-1252', 'ISO-8859-1']  # Add more encodings as necessary\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding, sep=\";\")\n",
    "            return encoding\n",
    "        \n",
    "        except UnicodeDecodeError:\n",
    "            continue  # Try next encoding if current one fails\n",
    "\n",
    "    # If all encodings fail\n",
    "    raise ValueError(\"Could not determine the encoding of the CSV file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_columns(df):\n",
    "    columns_to_keep = [\"article_no.\",\"quantity\"]\n",
    "    \n",
    "    try: \n",
    "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "        df = df.loc[:,columns_to_keep]\n",
    "        df.insert(0,\"kopfartikelnummer\",np.nan)\n",
    "        df.insert(1,\"kopfartikelname\",np.nan)\n",
    "        df.insert(2,\"kopfartikelbeschreibung\",np.nan)\n",
    "        df.insert(3,\"artikelname\",np.nan)\n",
    "        df.insert(4,\"artikelbeschreibung\",np.nan)\n",
    "        df.insert(5,\"positionsnummer\",np.nan)\n",
    "        df.rename(columns={\"article_no.\":\"articleNumber\"},inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_type_and_colour(df_grouped):\n",
    "    dummy = df_grouped[df_grouped[\"Artikelnummer\"].str.startswith((\"G.\", \"GF\"))]\n",
    "    \n",
    "    typ = dummy.iloc[0][\"Artikelnummer\"].split(\".\")[0]\n",
    "\n",
    "    if dummy.iloc[0][\"Artikelnummer\"].split(\".\")[1] == \"NB\":\n",
    "        colour = \"NB\"\n",
    "    elif dummy.iloc[0][\"Artikelnummer\"].split(\".\")[1] == \"NG\":\n",
    "        colour = \"NG\"\n",
    "    elif dummy.iloc[0][\"Artikelnummer\"].split(\".\")[1] == \"NW\":\n",
    "        colour = \"NW\"\n",
    "    \n",
    "    else:\n",
    "        print(\"coudn't recognize colour\")\n",
    "    \n",
    "    return typ,colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_sm4_case():\n",
    "    # test SM4\n",
    "    if not artikelliste_df_grouped[artikelliste_df_grouped[\"Artikelnummer\"].str.startswith(\"SM4\")].empty:\n",
    "        \n",
    "        dummy_grouped = artikelliste_df_grouped[artikelliste_df_grouped[\"Artikelnummer\"].str.startswith((\"G.\", \"GF\"))]\n",
    "\n",
    "        # test existing Grids and their colours \n",
    "        if artikelliste_df_grouped[artikelliste_df_grouped[\"Artikelnummer\"].str.startswith((\"G.\", \"GF\"))].shape[0] > 1:\n",
    "            print(\"The Cubes in this configuration do have different colours or are mixed with flame retardned and normal. The special case about SM4 cannot be solved now. Be aware.\")\n",
    "        \n",
    "        elif (dummy_grouped[\"Anzahl\"] <=2).any():\n",
    "            print(\"Zu wenige Grids in Liste. SM4 cant be solved. Be aware!\")\n",
    "        \n",
    "        else: \n",
    "\n",
    "            # normale Grids minus 2 \n",
    "            artikelliste_df_grouped.loc[artikelliste_df_grouped[\"Artikelnummer\"].str.startswith((\"G.\", \"GF\")), \"Anzahl\"] -= 2\n",
    "\n",
    "            # spezielle Grid + 1 je nach farbe\n",
    "            typ, colour = get_grid_type_and_colour(artikelliste_df_grouped)\n",
    "            artikelnummer = typ + \".\" + colour + \"_SM4\"\n",
    "            artikelliste_df_grouped.loc[len(artikelliste_df_grouped)]  = {\"Kopfartikelnummer\":kopfartikelnummer, \"Artikelnummer\":artikelnummer , \"Anzahl\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   kopfartikelnummer  kopfartikelname  kopfartikelbeschreibung  artikelname  \\\n",
      "2        testartikel              NaN                      NaN          NaN   \n",
      "3        testartikel              NaN                      NaN          NaN   \n",
      "4        testartikel              NaN                      NaN          NaN   \n",
      "5        testartikel              NaN                      NaN          NaN   \n",
      "6        testartikel              NaN                      NaN          NaN   \n",
      "7        testartikel              NaN                      NaN          NaN   \n",
      "8        testartikel              NaN                      NaN          NaN   \n",
      "9        testartikel              NaN                      NaN          NaN   \n",
      "10       testartikel              NaN                      NaN          NaN   \n",
      "11       testartikel              NaN                      NaN          NaN   \n",
      "\n",
      "    artikelbeschreibung  positionsnummer articleNumber  quantity  \n",
      "2                   NaN              NaN          G.NB        32  \n",
      "3                   NaN              NaN       P1.1.MB         1  \n",
      "4                   NaN              NaN       P1.1.MO         1  \n",
      "5                   NaN              NaN       P1.3.MB         1  \n",
      "6                   NaN              NaN       P1.4.MB         1  \n",
      "7                   NaN              NaN         PB.MB         8  \n",
      "8                   NaN              NaN         PB.MO         4  \n",
      "9                   NaN              NaN         PBI.B         3  \n",
      "10                  NaN              NaN         SS.MB        40  \n",
      "11                  NaN              NaN         SS.MO         8  \n",
      "Artikel mit Artikelnummer testartikel und Artikelname testerei erfolgreich erstellt\n"
     ]
    }
   ],
   "source": [
    "# create csv for upload\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".csv\"):\n",
    "        \n",
    "        kopfartikelnummer = file.split(\".\")[0]\n",
    "        encoding = detect_encoding(file)\n",
    "        \n",
    "        try:\n",
    "            artikelliste_df = pd.read_csv(file, sep=\";\", encoding=encoding)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        # get rid of empty Strings\n",
    "        artikelliste_df = artikelliste_df.apply(lambda x: x.replace(\"\", None))\n",
    "        \n",
    "        # query and group\n",
    "        artikelliste_df_grouped = artikelliste_df.groupby(\"Article No.\")[\"Quantity\"].sum().reset_index()\n",
    "        \n",
    "        # handle columns\n",
    "        artikelliste_df_grouped = handle_columns(artikelliste_df_grouped)\n",
    "        \n",
    "        # handle artikelnummer '0' & 'AP'\n",
    "        artikelliste_df_grouped = artikelliste_df_grouped.query(\"articleNumber != '0' and articleNumber != 'AP' \")\n",
    "\n",
    "        artikelliste_df_grouped[\"kopfartikelnummer\"] = kopfartikelnummer\n",
    "\n",
    "        # # solve special cases\n",
    "        # try:\n",
    "        #     solve_sm4_case()\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(e)\n",
    "        \n",
    "        #create article in weclapp and upload StÃ¼ckliste\n",
    "        try:\n",
    "            dics_to_upload = artikelliste_df_grouped[[\"articleNumber\",\"quantity\"]].to_dict(orient=\"records\")\n",
    "            article_number = kopfartikelnummer\n",
    "            article_name = input(f\"Wie lautet der Artikelname von {article_number}:\")\n",
    "            create_article(kopfartikelnummer, article_name, dics_to_upload)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with create_article function. Code: {e}\")\n",
    "        \n",
    "        # create finished csvs\n",
    "        artikelliste_df_grouped.to_csv(f\"finished_{kopfartikelnummer}.csv\", index=False, sep=\";\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prototyp um converter movable zu machen\n",
    "# # create csv for upload\n",
    "\n",
    "# working_directory = os.getcwd()\n",
    "# path_to_dir_with_csv = os.path.join(working_directory,\"..\")\n",
    "\n",
    "# for file in os.listdir(os.getcwd()):\n",
    "#     if file.endswith(\".csv\"):\n",
    "#         path_to_file = os.path.join(path_to_dir_with_csv,file)\n",
    "#         kopfartikelnummer = path_to_file.split(\".\")[0]\n",
    "#         encoding = detect_encoding(path_to_file)\n",
    "        \n",
    "#         try:\n",
    "#             artikelliste_df = pd.read_csv(path_to_file, sep=\";\", encoding=encoding)\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "        \n",
    "#         # get rid of empty Strings\n",
    "#         artikelliste_df = artikelliste_df.apply(lambda x: x.replace(\"\", None))\n",
    "        \n",
    "#         #query and group\n",
    "#         artikelliste_df.query(\"Pos.notnull()\", inplace=True)\n",
    "#         artikelliste_df_grouped = artikelliste_df.groupby(\"Bezeichnung\")[\"Menge\"].sum().reset_index()\n",
    "        \n",
    "#         handle_columns(artikelliste_df_grouped)\n",
    "        \n",
    "#         artikelliste_df_grouped[\"Kopfartikelnummer\"] = kopfartikelnummer\n",
    "\n",
    "#         # solve special cases\n",
    "#         try:\n",
    "#             solve_sm4_case()\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "        \n",
    "#         #create article in weclapp and upload StÃ¼ckliste\n",
    "#         try:\n",
    "#             artikelliste_df_grouped.rename(inplace=True, columns={\"Artikelnummer\":\"articleNumber\", \"Anzahl\":\"quantity\"})\n",
    "#             dics_to_upload = artikelliste_df_grouped[[\"articleNumber\",\"quantity\"]].to_dict(orient=\"records\")\n",
    "#             article_number = kopfartikelnummer\n",
    "#             article_name = input(f\"Wie lautet der Artikelname von {article_number}:\")\n",
    "#             create_article(kopfartikelnummer, article_name, dics_to_upload)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with create_article function. Code: {e}\")\n",
    "        \n",
    "#         # create finished csvs\n",
    "#         artikelliste_df_grouped.to_csv(f\"{path_to_dir_with_csv}/finished_{kopfartikelnummer}.csv\", index=False, sep=\";\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input(\"Press Enter to finish the script\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
